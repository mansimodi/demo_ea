{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Given:** \n",
    "       * Data contains keyword from tweet, \n",
    "       * location from where it was tweeted, \n",
    "       * text of the tweet, \n",
    "       * Tweet id. \n",
    "       * Target which is a binary classifier to determine if a tweet is about real disaster or not.\n",
    "\n",
    "**Problem:** To predict, based on training data, if a new tweet is related to real disaster or not. \n",
    "\n",
    "**Expected output:**\n",
    "         id, target(0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all the packages needed for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re \n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models.keyedvectors import FastTextKeyedVectors\n",
    "from gensim.models.fasttext import FastText\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "import fasttext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To display all rows in the df.\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the training data csv file** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\", header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape \n",
    "\n",
    "# 7613, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data.loc[:,['text', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can observe from the text snippet above, the data has**\n",
    "\n",
    "- punctuations, \n",
    "- numbers, \n",
    "- letters are both capital and small, \n",
    "- stopwords,\n",
    "- foreign characters, \n",
    "- urls and so on. \n",
    "\n",
    "We would like to remove all non english characters including the numbers from the text. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test.csv\", header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape\n",
    "\n",
    "# 3263, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_data.loc[:,['id','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data cleaning process**\n",
    "\n",
    "- Remove numbers\n",
    "- Remove punctuations\n",
    "- Remove urls\n",
    "- Remove whitespace\n",
    "- Remove stopwords\n",
    "- Remove non- printable words like \\n, \\r, \\t, and so on.\n",
    "- Convert text to lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_data(text):\n",
    "    \n",
    "   \n",
    "    # Remove numbers:\n",
    "    text = re.sub(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*','number',text)\n",
    "    \n",
    "    # Remove punctuations:\n",
    "    punct = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(punct)\n",
    "    \n",
    "    # Remove urls\n",
    "    text = re.sub(r'http\\S+','url',text)\n",
    "    \n",
    "    # Remove whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    \n",
    "    words_without_sw = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    text = ' '.join([str(elem) for elem in words_without_sw])\n",
    "    \n",
    "    # Remove non printable words\n",
    "    text = ''.join([word for word in text if word in string.printable])\n",
    "    \n",
    "    # convert text to lower:\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cleaned_txt'] = train['text'].apply(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['cleaned_txt'] = test['text'].apply(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>cleaned_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
       "      <td>1</td>\n",
       "      <td>residents asked shelter place notified officers evacuation shelter place orders expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "      <td>number people receive wildfires evacuation orders california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pours school</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    text  \\\n",
       "0                                                                  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                                                                 Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected   \n",
       "3                                                                      13,000 people receive #wildfires evacuation orders in California    \n",
       "4                                               Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "\n",
       "   target  \\\n",
       "0       1   \n",
       "1       1   \n",
       "2       1   \n",
       "3       1   \n",
       "4       1   \n",
       "\n",
       "                                                                                cleaned_txt  \n",
       "0                                              deeds reason earthquake may allah forgive us  \n",
       "1                                                     forest fire near la ronge sask canada  \n",
       "2  residents asked shelter place notified officers evacuation shelter place orders expected  \n",
       "3                              number people receive wildfires evacuation orders california  \n",
       "4                                   got sent photo ruby alaska smoke wildfires pours school  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = train.loc[:, ['cleaned_txt', 'target']]\n",
    "new_test = test.loc[:, ['id', 'cleaned_txt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_list = [i.split() for i in new_train.cleaned_txt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = FastText(corpus_list, \n",
    "                          size = 300,\n",
    "                          min_count = 5, \n",
    "                          window = 5, \n",
    "                          #min_alpha= 0.01, \n",
    "                          sg = 1,\n",
    "                          workers =1, \n",
    "                          sample = 1e-2)\n",
    "                                        \n",
    "# Refer : https://radimrehurek.com/gensim/models/fasttext.html\n",
    "\n",
    "# corpus list has the list of all words from the text\n",
    "# size = embedding size \n",
    "# min_count = The model ignores all words with total frequency lower than this.\n",
    "# window = The maximum distance between the current and predicted word within a sentence.\n",
    "# min_alpha = Learning rate will linearly drop to min_alpha as training progresses, default= 0.05\n",
    "# sg = loss function (ns - nskip gram, or cbow ) if sg=1, then sg otherwise CBOW\n",
    "# hs = loss function (hs - hierarchical softmax, negative sampling) if hs=1, hs is used or negative sampling.\n",
    "# sample = The threshold for configuring which higher-frequency words are randomly downsampled, useful range is (0, 1e-5).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  76308\n"
     ]
    }
   ],
   "source": [
    "print('vocab size: ', fasttext_model.corpus_total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('obama', 0.9957274198532104),\n",
       " ('declares', 0.9790096282958984),\n",
       " ('quarantine', 0.9708105325698853),\n",
       " ('saipan', 0.9642913341522217),\n",
       " ('quarantined', 0.9629697799682617),\n",
       " ('typhoondevastated', 0.9628607630729675),\n",
       " ('water', 0.960436224937439),\n",
       " ('migrant', 0.9564712643623352),\n",
       " ('signs', 0.9563822150230408),\n",
       " ('liked', 0.9539257287979126),\n",
       " ('reddit', 0.9512729048728943),\n",
       " ('migrants', 0.9454452395439148),\n",
       " ('center', 0.9450538158416748),\n",
       " ('view', 0.9450084567070007),\n",
       " ('devastated', 0.9426709413528442),\n",
       " ('register', 0.9423379898071289),\n",
       " ('declaration', 0.9423233866691589),\n",
       " ('sister', 0.9412342309951782),\n",
       " ('videos', 0.9407011866569519),\n",
       " ('minister', 0.9361927509307861)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('disaster', topn= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-69-9d65c336f20f>:1: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  fasttext_model.similar_by_word('natural', topn = 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ran', 0.9995251893997192),\n",
       " ('bbc', 0.9990274310112),\n",
       " ('manchester', 0.9989615082740784),\n",
       " ('israeli', 0.9989506006240845),\n",
       " ('research', 0.9989364147186279),\n",
       " ('disney', 0.9989258050918579),\n",
       " ('search', 0.9988222122192383),\n",
       " ('visit', 0.9986239671707153),\n",
       " ('disrupts', 0.9986175894737244),\n",
       " ('subreddits', 0.9986174702644348),\n",
       " ('signed', 0.99859619140625),\n",
       " ('mma', 0.9985911250114441),\n",
       " ('hundreds', 0.9984678030014038),\n",
       " ('trains', 0.9983665347099304),\n",
       " ('horse', 0.9983525276184082),\n",
       " ('hunters', 0.9981818199157715),\n",
       " ('plane', 0.9981813430786133),\n",
       " ('mens', 0.9981039762496948),\n",
       " ('israel', 0.9980775117874146),\n",
       " ('terror', 0.9980230331420898)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.similar_by_word('natural', topn = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-8a61a9d804e2>:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  fasttext_model.similarity('disaster', 'tragedy')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8664625"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculates cosine similarity between two words\n",
    "\n",
    "fasttext_model.similarity('disaster', 'tragedy') # 0.8664625\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-68-26c4cd81ea93>:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  fasttext_model.similarity('natural', 'disaster') # 0.91937894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.91937894"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.similarity('natural', 'disaster') # 0.91937894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df =[]\n",
    "for i in range(len(new_train)):\n",
    "    doc_fasttext = fasttext_model.wv.get_vector(new_train.iloc[i,0])\n",
    "    embeddings_df.append(doc_fasttext)\n",
    "embeddings_df = pd.DataFrame(embeddings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033558</td>\n",
       "      <td>-0.024403</td>\n",
       "      <td>0.012677</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>0.038067</td>\n",
       "      <td>-0.043989</td>\n",
       "      <td>-0.043146</td>\n",
       "      <td>-0.023853</td>\n",
       "      <td>0.010177</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013144</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>-0.009938</td>\n",
       "      <td>-0.060446</td>\n",
       "      <td>-0.011500</td>\n",
       "      <td>-0.041270</td>\n",
       "      <td>-0.003420</td>\n",
       "      <td>0.031375</td>\n",
       "      <td>-0.008691</td>\n",
       "      <td>-0.083189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027450</td>\n",
       "      <td>-0.020487</td>\n",
       "      <td>0.012470</td>\n",
       "      <td>0.013416</td>\n",
       "      <td>0.034127</td>\n",
       "      <td>-0.040573</td>\n",
       "      <td>-0.039100</td>\n",
       "      <td>-0.024721</td>\n",
       "      <td>0.010067</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015528</td>\n",
       "      <td>0.005523</td>\n",
       "      <td>-0.008618</td>\n",
       "      <td>-0.053386</td>\n",
       "      <td>-0.006213</td>\n",
       "      <td>-0.040029</td>\n",
       "      <td>-0.006108</td>\n",
       "      <td>0.026671</td>\n",
       "      <td>-0.007091</td>\n",
       "      <td>-0.075635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036895</td>\n",
       "      <td>-0.024925</td>\n",
       "      <td>0.014663</td>\n",
       "      <td>0.015435</td>\n",
       "      <td>0.044683</td>\n",
       "      <td>-0.053628</td>\n",
       "      <td>-0.052500</td>\n",
       "      <td>-0.032439</td>\n",
       "      <td>0.011942</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022521</td>\n",
       "      <td>0.008812</td>\n",
       "      <td>-0.013241</td>\n",
       "      <td>-0.067375</td>\n",
       "      <td>-0.005516</td>\n",
       "      <td>-0.054165</td>\n",
       "      <td>-0.008657</td>\n",
       "      <td>0.038309</td>\n",
       "      <td>-0.008397</td>\n",
       "      <td>-0.096951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061587</td>\n",
       "      <td>-0.039502</td>\n",
       "      <td>0.027822</td>\n",
       "      <td>0.045688</td>\n",
       "      <td>0.057635</td>\n",
       "      <td>-0.038430</td>\n",
       "      <td>-0.045401</td>\n",
       "      <td>-0.020154</td>\n",
       "      <td>0.007150</td>\n",
       "      <td>0.030538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017505</td>\n",
       "      <td>-0.013510</td>\n",
       "      <td>-0.001311</td>\n",
       "      <td>-0.112096</td>\n",
       "      <td>-0.047613</td>\n",
       "      <td>-0.060971</td>\n",
       "      <td>-0.004208</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>-0.011585</td>\n",
       "      <td>-0.158597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034165</td>\n",
       "      <td>-0.023508</td>\n",
       "      <td>0.010573</td>\n",
       "      <td>0.011611</td>\n",
       "      <td>0.040965</td>\n",
       "      <td>-0.048991</td>\n",
       "      <td>-0.048410</td>\n",
       "      <td>-0.027816</td>\n",
       "      <td>0.011852</td>\n",
       "      <td>-0.000834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021213</td>\n",
       "      <td>0.008798</td>\n",
       "      <td>-0.012595</td>\n",
       "      <td>-0.058015</td>\n",
       "      <td>-0.003370</td>\n",
       "      <td>-0.044388</td>\n",
       "      <td>-0.007006</td>\n",
       "      <td>0.036265</td>\n",
       "      <td>-0.008460</td>\n",
       "      <td>-0.083251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.033558 -0.024403  0.012677  0.015525  0.038067 -0.043989 -0.043146   \n",
       "1  0.027450 -0.020487  0.012470  0.013416  0.034127 -0.040573 -0.039100   \n",
       "2  0.036895 -0.024925  0.014663  0.015435  0.044683 -0.053628 -0.052500   \n",
       "3  0.061587 -0.039502  0.027822  0.045688  0.057635 -0.038430 -0.045401   \n",
       "4  0.034165 -0.023508  0.010573  0.011611  0.040965 -0.048991 -0.048410   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0 -0.023853  0.010177  0.003421  ... -0.013144  0.004529 -0.009938 -0.060446   \n",
       "1 -0.024721  0.010067  0.001231  ... -0.015528  0.005523 -0.008618 -0.053386   \n",
       "2 -0.032439  0.011942  0.000057  ... -0.022521  0.008812 -0.013241 -0.067375   \n",
       "3 -0.020154  0.007150  0.030538  ...  0.017505 -0.013510 -0.001311 -0.112096   \n",
       "4 -0.027816  0.011852 -0.000834  ... -0.021213  0.008798 -0.012595 -0.058015   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0 -0.011500 -0.041270 -0.003420  0.031375 -0.008691 -0.083189  \n",
       "1 -0.006213 -0.040029 -0.006108  0.026671 -0.007091 -0.075635  \n",
       "2 -0.005516 -0.054165 -0.008657  0.038309 -0.008397 -0.096951  \n",
       "3 -0.047613 -0.060971 -0.004208  0.006519 -0.011585 -0.158597  \n",
       "4 -0.003370 -0.044388 -0.007006  0.036265 -0.008460 -0.083251  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 300)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df.shape # 7613, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_embeddings = np.mean(embeddings_df, axis=0)\n",
    "sd_embeddings = embeddings_df.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the embeddings using the normalization formula.\n",
    "scaled_emb = []\n",
    "for i in range(300):\n",
    "    scaled_emb.append((embeddings_df[i] - mean_embeddings[i])/sd_embeddings[i])\n",
    "\n",
    "scaled_emb_transposed = pd.DataFrame(scaled_emb).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 300)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_emb_transposed.shape #7613, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaled_emb_transposed\n",
    "Y = new_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = []\n",
    "estimates.append(('LogisticRegression', Pipeline([('LR', LogisticRegression())])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model scores: \n",
    "model_scores = {}\n",
    "\n",
    "p_score = make_scorer(precision_score)\n",
    "r_score = make_scorer(recall_score)\n",
    "f1_score = make_scorer(f1_score)\n",
    "a_score = make_scorer(accuracy_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in estimates: \n",
    "    kfold = KFold(n_splits = 7, shuffle = True, random_state = 4)\n",
    "    p_scores = cross_val_score(i[1], X, new_train.target, cv = kfold, scoring = p_score)\n",
    "    r_scores = cross_val_score(i[1], X, new_train.target, cv = kfold, scoring = r_score)\n",
    "    f1_scores = cross_val_score(i[1], X, new_train.target, cv = kfold, scoring = f1_score)\n",
    "    a_scores = cross_val_score(i[1], X, new_train.target, cv = kfold, scoring = a_score)\n",
    "    \n",
    "    model_scores.update({ i[0]:{'accuracy': a_scores.mean(), 'f1_score':f1_scores.mean(), \n",
    "                                'precision': p_scores.mean(), 'recall':r_scores.mean()} })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in model_scores:\n",
    "    print('\\n', i)\n",
    "    print('\\n', model_scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and test data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "new_train['cleaned_txt'],\n",
    "new_train['target'],\n",
    "test_size = 0.25, # percentage of observations in test data \n",
    "random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(inplace = True,drop = True)\n",
    "y_train.reset_index(inplace = True,drop = True)\n",
    "\n",
    "X_valid.reset_index(inplace = True,drop = True)\n",
    "y_valid.reset_index(inplace = True,drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = fasttext.train_unsupervised('cleaned_col.txt', dim = 300, lr =0.1, epoch= 1,wordNgrams =2, loss = 'hs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save_model('result1.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
